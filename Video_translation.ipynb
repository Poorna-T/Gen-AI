{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYoJrhNgYsagR+4wjQ0Gf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poorna-T/Gen-AI/blob/main/Video_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlCxV_b93bqg"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install gradio transformers torch gtts moviepy openai-whisper --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import gradio as gr\n",
        "import moviepy.editor as mp\n",
        "import os\n",
        "from gtts import gTTS\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load Whisper model (this may take a moment)\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# Define translation models for South Indian languages and their gTTS language codes\n",
        "translation_models = {\n",
        "    \"English to Tamil\": {\"model\": \"Helsinki-NLP/opus-mt-en-ta\", \"tts_lang\": \"ta\"},\n",
        "    \"English to Telugu\": {\"model\": \"Helsinki-NLP/opus-mt-en-te\", \"tts_lang\": \"te\"},\n",
        "    \"English to Kannada\": {\"model\": \"Helsinki-NLP/opus-mt-en-kn\", \"tts_lang\": \"kn\"},\n",
        "    \"English to Malayalam\": {\"model\": \"Helsinki-NLP/opus-mt-en-ml\", \"tts_lang\": \"ml\"}\n",
        "}\n",
        "\n",
        "def process_video(video_file, target_language):\n",
        "    # Save the uploaded video file\n",
        "    input_video_path = \"input_video.mp4\"\n",
        "    with open(input_video_path, \"wb\") as f:\n",
        "        f.write(video_file.read())\n",
        "\n",
        "    # Load the video using MoviePy and extract its audio\n",
        "    video_clip = mp.VideoFileClip(input_video_path)\n",
        "    audio_path = \"extracted_audio.wav\"\n",
        "    video_clip.audio.write_audiofile(audio_path, logger=None)\n",
        "\n",
        "    # Transcribe the audio using Whisper\n",
        "    transcription_result = whisper_model.transcribe(audio_path)\n",
        "    original_text = transcription_result[\"text\"]\n",
        "\n",
        "    # Set up the translation pipeline using the selected model\n",
        "    model_name = translation_models[target_language][\"model\"]\n",
        "    translator = pipeline(\"translation\", model=model_name)\n",
        "    translation = translator(original_text)[0][\"translation_text\"]\n",
        "\n",
        "    # Generate new speech (TTS) for the translated text using gTTS\n",
        "    tts_language = translation_models[target_language][\"tts_lang\"]\n",
        "    tts = gTTS(text=translation, lang=tts_language)\n",
        "    tts_audio_path = \"translated_audio.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    # Load the generated TTS audio and set it as the audio for the original video\n",
        "    new_audio = mp.AudioFileClip(tts_audio_path)\n",
        "\n",
        "    # Set new audio track to the video\n",
        "    final_video = video_clip.set_audio(new_audio)\n",
        "    output_video_path = \"translated_video.mp4\"\n",
        "    final_video.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
        "\n",
        "    # Optional cleanup of temporary files\n",
        "    # os.remove(input_video_path)\n",
        "    # os.remove(audio_path)\n",
        "    # os.remove(tts_audio_path)\n",
        "\n",
        "    return output_video_path\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=[\n",
        "        gr.Video(label=\"Input Video (English)\"),\n",
        "        gr.Dropdown(choices=list(translation_models.keys()), label=\"Select Target Language\")\n",
        "    ],\n",
        "    outputs=gr.Video(label=\"Translated Video\"),\n",
        "    title=\"Video Translator with TTS\",\n",
        "    description=(\n",
        "        \"Upload a video with English speech. The system will transcribe, translate to a South Indian language, \"\n",
        "        \"generate new speech for the translation, and output a video with the new audio track.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch(share=True)\n",
        "```\n",
        "\n",
        "Let me know if you'd like to optimize runtime, improve UI, or add features like subtitle overlay!"
      ]
    }
  ]
}